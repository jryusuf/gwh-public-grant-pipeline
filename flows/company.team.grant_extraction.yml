id: grant_extraction
namespace: company.team

inputs:
  - id: extraction_id
    type: STRING
    defaults: "e4937001-55df-4c93-af9b-c17438c509e6"

tasks:
  - id: extract_raw_grants
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - pip install pydantic google-genai supabase kestra
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    containerImage: python:3.14-slim
    warningOnStdErr: false
    retry:
      type: constant
      interval: PT1M
      maxAttempt: 10
    script: |
      from google import genai
      from pydantic import BaseModel
      from supabase import create_client, Client
      from kestra import Kestra
      import json

      logger = Kestra.logger()

      url = "{{kv('supabase_url')}}"
      key = "{{kv('supabase_key')}}"
      supabase: Client = create_client(url, key)

      class Grant(BaseModel):
        grant_name: str
        grant_organisation: str
        grant_amount: str
        grant_date: str
        grant_url: str
        grant_description: str
        grant_eligibility: str


      markdowns = []

      extraction = (supabase.table("extractions").select("*").eq("id", "{{trigger.body["record"]["id"]}}").execute())

      for i in range(1, 11):
            result_key = f"result_{i}"
            markdown = (supabase.table("scrape_results").select("markdown").eq("id", extraction.data[0][result_key]).execute())
            markdowns.append(markdown.data[0])
      
 
      instructions = {{kv('extraction_system_prompt')}}
      content = markdowns

      client = genai.Client(api_key="{{kv('gemini_api_key')}}")
      response = client.models.generate_content(
          model="{{kv('gemini_model')}}",
          contents=str(content),
          config={
              "response_mime_type": "application/json",
              "response_schema": list[Grant],
              "system_instruction" : instructions
          }
      )

      logger.info("Saving extracted raw grant data")
      link_list = []
      new_grant_ids = []
      try:
        for grant in response.parsed:
          link_list.append(grant.grant_url)
          raw_result = (supabase.table("raw_grants").insert({
            "extraction_id": "{{trigger.body["record"]["id"]}}",
            "grant_name": grant.grant_name,
            "grant_organisation": grant.grant_organisation,
            "grant_amount": grant.grant_amount,
            "grant_date": grant.grant_date,
            "grant_url": grant.grant_url,
            "grant_description": grant.grant_description,
            "grant_eligibility": grant.grant_eligibility
          }).execute())
          if raw_result.data:
              new_grant_ids.append(raw_result.data[0]['id'])
      except Exception as e:
        logger.error("Error, probably no grant data was found")

      logger.info(f"Updating extraction status and tokens")
      updated_extraction = (supabase.table("extractions").update({
        "status": "complete",
        "tokens":  {
          "candidates_token_count" : response.usage_metadata.candidates_token_count,
          "prompt_token_count" : response.usage_metadata.prompt_token_count, 
          "thoughts_token_count" : response.usage_metadata.thoughts_token_count, 
          "total_token_count" : response.usage_metadata.total_token_count,  
        }
      }).eq("id", "{{trigger.body["record"]["id"]}}").execute())
      logger.info(f"Updated extraction: {updated_extraction}")

      logger.info("Updating scrape results status for extraction urls")
      for i in range(1, 11):
            result_key = f"result_{i}"
            scrape_result_id = extraction.data[0][result_key]
            update_result = (supabase.table("scrape_results").update({
              "extraction_status" : "complete"
            }).eq("id", scrape_result_id).execute())
            logger.info(f'Update complete for scrape result: {update_result.data[0]["id"]}')
      Kestra.outputs({
          "link_list": link_list,
          "new_grant_id_list": new_grant_ids
      })

  # This task can still run in parallel as it doesn't depend on the vector/cluster steps
  - id: extract_domains
    type: io.kestra.plugin.core.flow.Subflow
    namespace: company.team
    flowId: domain_extraction
    wait: true
    inputs:
      url_list: "{{outputs.extract_raw_grants.vars.link_list}}"

  # This 'Sequential' task group ensures the tasks inside run in the order they are listed
  - id: processing_pipeline
    type: io.kestra.plugin.core.flow.Sequential
    tasks:
      - id: run_vectorization
        type: io.kestra.plugin.core.flow.Subflow
        namespace: company.team
        flowId: grant_vectorizer_batch
        wait: true
        inputs:
          grant_id_list: "{{outputs.extract_raw_grants.vars.new_grant_id_list}}"

      - id: run_clustering
        type: io.kestra.plugin.core.flow.Subflow
        namespace: company.team
        flowId: grant_cluster_processor
        wait: true
        inputs:
          # This still uses the original output, but because it's in a Sequential
          # task, it is guaranteed to run AFTER run_vectorization completes.
          grant_id_list: "{{outputs.extract_raw_grants.vars.new_grant_id_list}}"

triggers:
  - id: webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: extract